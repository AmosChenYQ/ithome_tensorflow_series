//
// Generated by LLVM NVPTX Back-End
//

.version 6.0
.target sm_61
.address_size 64

	// .globl	broadcast_24
.visible .global .align 128 .b8 buffer_for_constant_38[4] = {119, 190, 127, 63};
.visible .global .align 128 .b8 buffer_for_constant_37[4] = {102, 102, 102, 63};
.visible .global .align 128 .b8 buffer_for_constant_7[4];
.visible .global .align 128 .b8 buffer_for_constant_5[4] = {205, 204, 204, 61};

.visible .entry broadcast_24(
	.param .u64 broadcast_24_param_0
)
.reqntid 5, 1, 1
{
	.reg .b32 	%r<3>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [broadcast_24_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %tid.x;
	shl.b32 	%r2, %r1, 1;
	mul.wide.u32 	%rd3, %r2, 4;
	add.s64 	%rd4, %rd2, %rd3;
	mov.f32 	%f1, 0f00000000;
	st.global.v2.f32 	[%rd4], {%f1, %f1};
	ret;

}
	// .globl	broadcast_22
.visible .entry broadcast_22(
	.param .u64 broadcast_22_param_0
)
.reqntid 5, 1, 1
{
	.reg .b32 	%r<3>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [broadcast_22_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %tid.x;
	shl.b32 	%r2, %r1, 1;
	mul.wide.u32 	%rd3, %r2, 4;
	add.s64 	%rd4, %rd2, %rd3;
	mov.f32 	%f1, 0f3DCCCCCD;
	st.global.v2.f32 	[%rd4], {%f1, %f1};
	ret;

}
	// .globl	broadcast_8
.visible .entry broadcast_8(
	.param .u64 broadcast_8_param_0
)
.reqntid 125, 1, 1
{
	.reg .b32 	%r<3>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [broadcast_8_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %tid.x;
	shl.b32 	%r2, %r1, 2;
	mul.wide.u32 	%rd3, %r2, 4;
	add.s64 	%rd4, %rd2, %rd3;
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[%rd4], {%f1, %f1, %f1, %f1};
	ret;

}
	// .globl	broadcast_6
.visible .entry broadcast_6(
	.param .u64 broadcast_6_param_0
)
.reqntid 125, 1, 1
{
	.reg .b32 	%r<3>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<5>;

	ld.param.u64 	%rd1, [broadcast_6_param_0];
	cvta.to.global.u64 	%rd2, %rd1;
	mov.u32 	%r1, %tid.x;
	shl.b32 	%r2, %r1, 2;
	mul.wide.u32 	%rd3, %r2, 4;
	add.s64 	%rd4, %rd2, %rd3;
	mov.f32 	%f1, 0f3DCCCCCD;
	st.global.v4.f32 	[%rd4], {%f1, %f1, %f1, %f1};
	ret;

}
	// .globl	broadcast_34
.visible .entry broadcast_34(
	.param .u64 broadcast_34_param_0
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .f32 	%f<2>;
	.reg .b64 	%rd<5>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 10;
	shl.b32 	%r5, %r3, 2;
	or.b32  	%r1, %r4, %r5;
	setp.lt.u32 	%p1, %r1, 5000;
	@%p1 bra 	$L__BB4_2;
	bra.uni 	$L__BB4_1;
$L__BB4_2:
	ld.param.u64 	%rd2, [broadcast_34_param_0];
	cvta.to.global.u64 	%rd1, %rd2;
	mul.wide.u32 	%rd3, %r1, 4;
	add.s64 	%rd4, %rd1, %rd3;
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[%rd4], {%f1, %f1, %f1, %f1};
$L__BB4_1:
	ret;

}
	// .globl	fusion
.visible .entry fusion(
	.param .u64 fusion_param_0,
	.param .u64 fusion_param_1
)
.reqntid 256, 1, 1
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .f32 	%f<9>;
	.reg .b64 	%rd<8>;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r4, %r2, 10;
	shl.b32 	%r5, %r3, 2;
	or.b32  	%r1, %r4, %r5;
	setp.lt.u32 	%p1, %r1, 5000;
	@%p1 bra 	$L__BB5_2;
	bra.uni 	$L__BB5_1;
$L__BB5_2:
	ld.param.u64 	%rd3, [fusion_param_0];
	ld.param.u64 	%rd4, [fusion_param_1];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd3;
	mul.wide.u32 	%rd5, %r1, 4;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.nc.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd6];
	mul.rn.f32 	%f5, %f1, 0f3DCCCCCD;
	add.s64 	%rd7, %rd1, %rd5;
	mul.rn.f32 	%f6, %f2, 0f3DCCCCCD;
	mul.rn.f32 	%f7, %f3, 0f3DCCCCCD;
	mul.rn.f32 	%f8, %f4, 0f3DCCCCCD;
	st.global.v4.f32 	[%rd7], {%f5, %f6, %f7, %f8};
$L__BB5_1:
	ret;

}
	// .globl	broadcast_18
.visible .entry broadcast_18(
	.param .u64 broadcast_18_param_0
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<12>;
	.reg .f32 	%f<3>;
	.reg .b64 	%rd<9>;

	ld.param.u64 	%rd4, [broadcast_18_param_0];
	cvta.to.global.u64 	%rd5, %rd4;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	shl.b32 	%r7, %r5, 9;
	shl.b32 	%r8, %r6, 2;
	or.b32  	%r1, %r7, %r8;
	mul.wide.u32 	%rd6, %r1, 4;
	add.s64 	%rd7, %rd6, %rd5;
	add.s64 	%rd8, %rd7, 98316;
	mov.u32 	%r11, 24576;
	mov.f32 	%f1, 0f00000000;
	bra.uni 	$L__BB6_1;
$L__BB6_3:
	add.s32 	%r3, %r11, 49152;
	add.s32 	%r10, %r11, -24576;
	add.s64 	%rd8, %rd8, 196608;
	setp.lt.u32 	%p2, %r10, 342848;
	mov.u32 	%r11, %r3;
	@%p2 bra 	$L__BB6_1;
	bra.uni 	$L__BB6_4;
$L__BB6_1:
	st.global.v4.f32 	[%rd8+-98316], {%f1, %f1, %f1, %f1};
	add.s32 	%r9, %r1, %r11;
	setp.gt.u32 	%p1, %r9, 391999;
	@%p1 bra 	$L__BB6_3;
	st.global.v4.f32 	[%rd8+-12], {%f1, %f1, %f1, %f1};
	bra.uni 	$L__BB6_3;
$L__BB6_4:
	ret;

}
	// .globl	fusion_1
.visible .entry fusion_1(
	.param .u64 fusion_1_param_0,
	.param .u64 fusion_1_param_1
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<12>;
	.reg .f32 	%f<17>;
	.reg .b64 	%rd<15>;

	ld.param.u64 	%rd7, [fusion_1_param_0];
	ld.param.u64 	%rd8, [fusion_1_param_1];
	cvta.to.global.u64 	%rd9, %rd8;
	cvta.to.global.u64 	%rd10, %rd7;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	shl.b32 	%r7, %r5, 9;
	shl.b32 	%r8, %r6, 2;
	or.b32  	%r1, %r7, %r8;
	mul.wide.u32 	%rd11, %r1, 4;
	add.s64 	%rd12, %rd11, 98316;
	add.s64 	%rd14, %rd10, %rd12;
	add.s64 	%rd13, %rd9, %rd12;
	mov.u32 	%r11, 24576;
	bra.uni 	$L__BB7_1;
$L__BB7_3:
	add.s32 	%r3, %r11, 49152;
	add.s32 	%r10, %r11, -24576;
	add.s64 	%rd14, %rd14, 196608;
	add.s64 	%rd13, %rd13, 196608;
	setp.lt.u32 	%p2, %r10, 342848;
	mov.u32 	%r11, %r3;
	@%p2 bra 	$L__BB7_1;
	bra.uni 	$L__BB7_4;
$L__BB7_1:
	ld.global.nc.v4.f32 	{%f1, %f2, %f3, %f4}, [%rd14+-98316];
	mul.rn.f32 	%f5, %f1, 0f3DCCCCCD;
	mul.rn.f32 	%f6, %f2, 0f3DCCCCCD;
	mul.rn.f32 	%f7, %f3, 0f3DCCCCCD;
	mul.rn.f32 	%f8, %f4, 0f3DCCCCCD;
	st.global.v4.f32 	[%rd13+-98316], {%f5, %f6, %f7, %f8};
	add.s32 	%r9, %r1, %r11;
	setp.gt.u32 	%p1, %r9, 391999;
	@%p1 bra 	$L__BB7_3;
	ld.global.nc.v4.f32 	{%f9, %f10, %f11, %f12}, [%rd14+-12];
	mul.rn.f32 	%f13, %f9, 0f3DCCCCCD;
	mul.rn.f32 	%f14, %f10, 0f3DCCCCCD;
	mul.rn.f32 	%f15, %f11, 0f3DCCCCCD;
	mul.rn.f32 	%f16, %f12, 0f3DCCCCCD;
	st.global.v4.f32 	[%rd13+-12], {%f13, %f14, %f15, %f16};
	bra.uni 	$L__BB7_3;
$L__BB7_4:
	ret;

}
